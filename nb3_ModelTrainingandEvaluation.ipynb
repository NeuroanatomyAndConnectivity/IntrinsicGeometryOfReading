{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716a27dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import CCAtools\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import wilcoxon\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d1291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2PermCCA = \"PermCCA/\"  ### https://github.com/andersonwinkler/PermCCA\n",
    "### note environment requirement being phased out ^^\n",
    "palmPath = \"palm-alpha119_2/\"  ### path to palm\n",
    "### see https://github.com/andersonwinkler/PALM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f6356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matlab.engine as mlab_eng\n",
    "import matlab\n",
    "\n",
    "eng = mlab_eng.start_matlab()\n",
    "eng.addpath(path2PermCCA)\n",
    "eng.addpath(palmPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3a2a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CCAtools.preprocessing import (\n",
    "    prep_confounds,\n",
    "    cube_root,\n",
    "    gauss_SM,\n",
    "    zscore,\n",
    "    normal_eqn_python,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700f7394",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "add00a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### set paths\n",
    "restricted_hcp_path = \"\"  ## set path to your copy of hcp restricted data\n",
    "hcp_behavior_data = \"\"  ### set path to your copy of hcp behvaioral data\n",
    "data_dir = \"\"  ### set to directory for data used in/throughout analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11f9b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load behavioral data\n",
    "### this is HCP restricted data. for access see\n",
    "### https://www.humanconnectome.org/study/hcp-young-adult/document/restricted-data-usage\n",
    "RestrictedData = pd.read_csv(restricted_hcp_path, index_col=\"Subject\")\n",
    "### load non-restricted hcp behavioral data\n",
    "BehData = pd.read_csv(hcp_behavior_data, index_col=\"Subject\")\n",
    "### merge the dtaframes\n",
    "fullData = BehData.merge(RestrictedData, on=\"Subject\")\n",
    "fullData.index = fullData.index.map(str)\n",
    "fullData.index = fullData.index.map(str)\n",
    "### load in square_root of total hemisphere surface area for each subject\n",
    "Larea = pd.read_csv(f\"{data_dir}/LareaFactors.csv\")\n",
    "Larea.rename(index={0: \"Larea\"}, inplace=True)\n",
    "Rarea = pd.read_csv(f\"{data_dir}/RareaFactors.csv\")\n",
    "Rarea.rename(index={0: \"Rarea\"}, inplace=True)\n",
    "area = pd.concat([Larea, Rarea]).T\n",
    "area.index.names = [\"Subject\"]\n",
    "fullData = area.join(fullData, on=\"Subject\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5551bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load Distances\n",
    "LSchaeferDist = pd.read_csv(f\"{data_dir}/Schaefer400Geodesic.L.mat.csv\")\n",
    "LSchaeferDist.rename(columns={\"Unnamed: 0\": \"Subject\"}, inplace=True)\n",
    "LSchaeferDist.set_index(\"Subject\", inplace=True)\n",
    "LSchaeferDist.columns = [f\"L.{i}\" for i in LSchaeferDist.columns]\n",
    "\n",
    "RSchaeferDist = pd.read_csv(f\"{data_dir}/Schaefer400Geodesic.R.mat.csv\")\n",
    "RSchaeferDist.rename(columns={\"Unnamed: 0\": \"Subject\"}, inplace=True)\n",
    "RSchaeferDist.set_index(\"Subject\", inplace=True)\n",
    "RSchaeferDist.columns = [f\"R.{i}\" for i in RSchaeferDist.columns]\n",
    "SchaeferDist = pd.concat([LSchaeferDist, RSchaeferDist], axis=1)\n",
    "SchaeferDist.index = SchaeferDist.index.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbf4c6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load FC data\n",
    "LSchaeferFC = pd.read_csv(f\"{data_dir}/Schaefer200FConn.L.mat.csv\")\n",
    "LSchaeferFC.rename(columns={\"Unnamed: 0\": \"Subject\"}, inplace=True)\n",
    "LSchaeferFC.set_index(\"Subject\", inplace=True)\n",
    "LSchaeferFC.columns = [f\"L.{i}\" for i in LSchaeferFC.columns]\n",
    "\n",
    "RSchaeferFC = pd.read_csv(f\"{data_dir}/Schaefer200FConn.R.mat.csv\")\n",
    "RSchaeferFC.rename(columns={\"Unnamed: 0\": \"Subject\"}, inplace=True)\n",
    "RSchaeferFC.set_index(\"Subject\", inplace=True)\n",
    "RSchaeferFC.columns = [f\"R.{i}\" for i in RSchaeferFC.columns]\n",
    "SchaeferFC = pd.concat([LSchaeferFC, RSchaeferFC], axis=1)\n",
    "SchaeferFC.index = SchaeferFC.index.map(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e113ccf7",
   "metadata": {},
   "source": [
    "## Define preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fb0059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### preprocessing functions we'll add to a package later\n",
    "from CCAtools.preprocessing import zscore\n",
    "\n",
    "\n",
    "def prep_confounds_local(confs, eng):\n",
    "    \"\"\"set the confounds up with gaussianization and normalization as done by smith et al 2015.\"\"\"\n",
    "    assert (\"palm\" in eng.path()) == True, \"add PermCCA to your matlab path\"\n",
    "    mat_data = matlab.double(\n",
    "        confs.values.tolist()\n",
    "    )  ### they actually included the binary acquisition data in the gaussianization\n",
    "    #     print('gaussianizing')\n",
    "    gaussed = np.asarray(eng.palm_inormal(mat_data))\n",
    "    squared = gaussed[:, 1:] ** 2\n",
    "    ready_confs = np.hstack([gaussed, squared])\n",
    "    ready_confs = zscore(np.hstack([gaussed, squared]), ax=0)\n",
    "\n",
    "    return ready_confs\n",
    "\n",
    "\n",
    "def set_confounds(data, mlab_eng):\n",
    "    \"\"\"takes in a full data set of all HCP variables and extracts and preprocesses confounds to be regressed\"\"\"\n",
    "    eng = mlab_eng\n",
    "    confounds = data\n",
    "    gend = LabelEncoder().fit_transform(confounds[\"Gender\"])\n",
    "    acq = LabelEncoder().fit_transform(confounds[\"Acquisition\"])\n",
    "    acq[acq < 2] = 0\n",
    "    acq[acq > 0] = 1\n",
    "    df = confounds.copy()\n",
    "    df[\"Acquisition\"] = acq\n",
    "    df[\"Gender\"] = gend\n",
    "    df[\"FS_IntraCranial_Vol\"] = data[\"FS_IntraCranial_Vol\"].map(cube_root)\n",
    "    df[\"FS_BrainSeg_Vol\"] = data[\"FS_BrainSeg_Vol\"].map(cube_root)\n",
    "    df[\"Larea\"] = data[\"Larea\"].map(np.sqrt)\n",
    "    df[\"Rarea\"] = data[\"Rarea\"].map(np.sqrt)\n",
    "    confounds = prep_confounds_local(df, eng)\n",
    "    return confounds\n",
    "\n",
    "\n",
    "def preprocess_SM(data, confs, mlab_eng):\n",
    "    \"\"\"preprocess the subject measures. Guassianize and remove confounds.\"\"\"\n",
    "    eng = mlab_eng\n",
    "    assert (\"palm\" in eng.path()) == True, \"add PermCCA to your matlab path\"\n",
    "    data = data\n",
    "    gaussed = gauss_SM(data, eng)\n",
    "    residuals = normal_eqn_python(confs, gaussed)\n",
    "    cleaned = zscore(residuals)\n",
    "    cleaned = pd.DataFrame(cleaned, index=data.index, columns=data.columns)\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def preprocessDists(data, confounds):\n",
    "    NET = data.copy()\n",
    "    dims = NET.shape\n",
    "    ##### check for vertices with no variance i.e guaranteed masks\n",
    "    steady_masks = np.where(np.sum(NET) == 0)[0]\n",
    "    valididx = np.where(np.sum(NET) != 0)[0]\n",
    "\n",
    "    if len(steady_masks) != 0:\n",
    "        NET = NET.iloc[:, valididx]\n",
    "\n",
    "    #     amNET = np.abs(np.nanmean(NET, axis=0))\n",
    "    NET1 = NET  # /amNET\n",
    "    NET1 = NET1 - np.mean(NET1, axis=0)\n",
    "    NET1 = NET1 / np.nanstd(NET1.values.flatten())\n",
    "    NET1 = normal_eqn_python(confounds, NET1)\n",
    "    NET1 = pd.DataFrame(NET1, columns=NET.columns, index=data.index)\n",
    "\n",
    "    if len(steady_masks) != 0:\n",
    "        out = np.zeros(dims)\n",
    "        out[:, valididx] = NET1.values\n",
    "        NET1 = pd.DataFrame(out, index=NET.index)\n",
    "\n",
    "    return NET1\n",
    "\n",
    "\n",
    "def clean_data(subjectList, all_confs, all_SM, all_dist, mlab=eng):\n",
    "    ### remove confounds for a group of subjects\n",
    "    ### always done independently to avoid leakage\n",
    "\n",
    "    ## set the confounds\n",
    "    confs = all_confs.loc[subjectList]\n",
    "    confs = set_confounds(confs, mlab)\n",
    "    ## regress them from behavioral measures\n",
    "    behavior = all_SM.loc[subjectList]\n",
    "    behavior = preprocess_SM(behavior, confs, mlab)\n",
    "    ## regress them from distance measures\n",
    "    distance = all_dist.loc[subjectList]\n",
    "    distance = preprocessDists(distance, confs)\n",
    "\n",
    "    return confs, behavior, distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92817c85",
   "metadata": {},
   "source": [
    "#### Extract confounds and behaviors of interest from raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd9f32c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_categories = fullData[\n",
    "    [\n",
    "        \"Acquisition\",\n",
    "        \"Gender\",\n",
    "        \"Age_in_Yrs\",\n",
    "        \"Height\",\n",
    "        \"Weight\",\n",
    "        \"BPSystolic\",\n",
    "        \"BPDiastolic\",\n",
    "        \"FS_IntraCranial_Vol\",\n",
    "        \"FS_BrainSeg_Vol\",\n",
    "        \"Larea\",\n",
    "        \"Rarea\",\n",
    "    ]\n",
    "]\n",
    "# conf_categories.dropna(inplace=True)\n",
    "\n",
    "SensoryTasks = [\"ReadEng_Unadj\"]\n",
    "# subjects=list(fullData.index)\n",
    "subjSM = fullData[SensoryTasks]\n",
    "\n",
    "\n",
    "full_subjList = conf_categories.merge(subjSM, on=\"Subject\").dropna().index\n",
    "full_subjList.to_series().to_csv(\"SubjectInclusionList.csv\")\n",
    "\n",
    "conf_categories = conf_categories.loc[full_subjList]\n",
    "subjSM = subjSM.loc[full_subjList]\n",
    "\n",
    "complete_data = fullData.loc[full_subjList]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd477cb",
   "metadata": {},
   "source": [
    "### Load prebaked cross validation as in feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ffe3f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Opening JSON file\n",
    "f = open(\"cross_validation_folds.json\")\n",
    "\n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "folds = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9f7158",
   "metadata": {},
   "source": [
    "### Load positive and negative distances associated with reading \n",
    "The json file loaded uses distances with a threshold set at 0.01, a standard threhsold used often in connectome predictive modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1c8414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### distances\n",
    "with open(\"positive_distances.json\") as json_file:\n",
    "    positiveDistances = json.load(json_file)\n",
    "\n",
    "with open(\"negativeDistances.json\") as json_file:\n",
    "    negativeDistances = json.load(json_file)\n",
    "### FC edges\n",
    "with open(\"positiveFC.json\") as json_file:\n",
    "    positiveFC = json.load(json_file)\n",
    "\n",
    "with open(\"negativeFC.json\") as json_file:\n",
    "    negativeFC = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8342877c",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1278773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(subjectList, all_confs, all_SM, all_dist, mlab=eng):\n",
    "    ### remove confounds for a group of subjects\n",
    "    ### always done independently to avoid leakage\n",
    "\n",
    "    ## set the confounds\n",
    "    confs = all_confs.loc[subjectList]\n",
    "    confs = set_confounds(confs, mlab)\n",
    "    ## regress them from behavioral measures\n",
    "    behavior = all_SM.loc[subjectList]\n",
    "    behavior = preprocess_SM(behavior, confs, mlab)\n",
    "    ## regress them from distance measures\n",
    "    distance = all_dist.loc[subjectList]\n",
    "    distance = preprocessDists(distance, confs)\n",
    "\n",
    "    return confs, behavior, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57e64f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01a155b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = \"ReadEng_Unadj\"  ### this notebook runs on reading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0eee77",
   "metadata": {},
   "source": [
    "This is the most basic version of CPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "174db351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc174840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_summary_measures(task, edges, Dist, ablate=False):\n",
    "    \"\"\"Prepares summary measures for analysis based on edges.\n",
    "\n",
    "    Parameters:\n",
    "    task (str): The specific task for which edges are being analyzed.\n",
    "    edges (dict or list): A dictionary of edges for multiple tasks or a list of edge lists (positive and negative).\n",
    "    Dist (pd.DataFrame): A DataFrame containing distance measures for edges.\n",
    "    ablate (list, optional): A list of edges to include in the summary measure. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the summary measure for the specified task.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if edges is a dictionary (single task mode) or a list (positive and negative edges)\n",
    "    single_status = isinstance(edges, dict)\n",
    "    if single_status:\n",
    "        edge_list = edges[task]\n",
    "        n_edges = len(edge_list)\n",
    "        if ablate:\n",
    "            edge_list = [j for j in edge_list if j in ablate]\n",
    "\n",
    "    else:\n",
    "        edge_list = {\"pos\": edges[0][task], \"neg\": edges[1][task]}\n",
    "        n_edges = len(edge_list[\"pos\"]) + len(edge_list[\"neg\"])\n",
    "\n",
    "        if ablate:\n",
    "            # Filter edges based on ablate list\n",
    "            pos = [j for j in edge_list[\"pos\"] if j in ablate]\n",
    "            neg = [j for j in edge_list[\"neg\"] if j in ablate]\n",
    "\n",
    "            edge_list = {\"pos\": pos, \"neg\": neg}\n",
    "\n",
    "            # Logging included edges\n",
    "            if pos:\n",
    "                print(f\"{len(pos)} positive edges included\")\n",
    "            if neg:\n",
    "                print(f\"{len(neg)} negative edges included\")\n",
    "\n",
    "    # Calculate the summary measure based on the edge list\n",
    "    #     print(edge_list)\n",
    "    if single_status:\n",
    "        summary_measure = pd.DataFrame(Dist[edge_list].sum(axis=1))\n",
    "        print(f\"{len(edge_list)}/{n_edges} edges used in summary metric\")\n",
    "    else:\n",
    "        p_n_Edge = len(edge_list[\"pos\"])\n",
    "        n_n_Edge = len(edge_list[\"neg\"])\n",
    "        print(f\"{p_n_Edge + n_n_Edge}/{n_edges} edges used in summary metric\")\n",
    "\n",
    "        if p_n_Edge > 0 and n_n_Edge == 0:\n",
    "            summary_measure = pd.DataFrame(Dist[edge_list[\"pos\"]].sum(axis=1))\n",
    "        elif p_n_Edge == 0 and n_n_Edge > 0:\n",
    "            summary_measure = pd.DataFrame(Dist[edge_list[\"neg\"]].sum(axis=1))\n",
    "        else:\n",
    "            summary_measure = pd.DataFrame(\n",
    "                [Dist[edge_list[\"pos\"]].sum(axis=1), Dist[edge_list[\"neg\"]].sum(axis=1)]\n",
    "            ).T\n",
    "\n",
    "    return summary_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78b2effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def clean_folds(task, cv_folds, confounds, Beh, SummaryMeasures, mlab=eng):\n",
    "    training_dist = {}\n",
    "    training_beh = {}\n",
    "\n",
    "    val_dist = {}\n",
    "    val_beh = {}\n",
    "    for fold in cv_folds:\n",
    "        #### get the subject ID's for each fold\n",
    "        training_idx = cv_folds[fold][\"training\"]\n",
    "        val_idx = cv_folds[fold][\"testing\"]\n",
    "        ### extract confounds\n",
    "        ### get confounds training set\n",
    "        confs_train = confounds.loc[training_idx]\n",
    "        confs_train = set_confounds(confs_train, mlab)\n",
    "        ### get confounds validation\n",
    "        confs_val = confounds.loc[val_idx]\n",
    "        confs_val = set_confounds(confs_val, mlab)\n",
    "        ### clean behavioral variables\n",
    "        #         print('cleaning behavioral data')\n",
    "        beh_train = preprocess_SM(Beh.loc[training_idx], confs_train, mlab)[task]\n",
    "\n",
    "        beh_val = preprocess_SM(Beh.loc[val_idx], confs_val, mlab)[\n",
    "            task\n",
    "        ]  ### the valiadtoin data remains untouched\n",
    "        ### clean distance data\n",
    "        #         print('training task dist models')\n",
    "        train_d = SummaryMeasures.loc[training_idx]\n",
    "        train_d = preprocessDists(train_d, confs_train)\n",
    "        ### extract validatoin set data\n",
    "        val_d = SummaryMeasures.loc[val_idx]\n",
    "        val_d = preprocessDists(val_d, confs_val)\n",
    "\n",
    "        training_beh[fold] = beh_train\n",
    "        training_dist[fold] = train_d\n",
    "        val_dist[fold] = val_d\n",
    "        val_beh[fold] = beh_val\n",
    "\n",
    "    return training_dist, training_beh, val_dist, val_beh\n",
    "\n",
    "\n",
    "def train_test_predict(trainX, trainY, valX, valY):\n",
    "    # Set up the pipeline with StandardScaler and LinearRegression\n",
    "    lr = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler()),  # Scale features\n",
    "            (\"reg\", LinearRegression(fit_intercept=True)),  # Apply linear regression\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # No need to reshape inside the function; let's handle outside if needed\n",
    "    # Fit the model\n",
    "    lr.fit(trainX, trainY)\n",
    "\n",
    "    # Predict using the model\n",
    "    predY = lr.predict(valX)\n",
    "    r, p = pearsonr(predY.squeeze(), valY)\n",
    "\n",
    "    # Extract coefficients and intercept\n",
    "    coefficients = lr.named_steps[\"reg\"].coef_\n",
    "    intercept = lr.named_steps[\"reg\"].intercept_\n",
    "    mse = mean_squared_error(valY, predY)\n",
    "\n",
    "    return r, coefficients, intercept, mse\n",
    "\n",
    "\n",
    "def fit_and_measure(training_dist, training_beh, val_dist, val_beh, skip_perms=False):\n",
    "    corr_dict = {}\n",
    "    beta_dict = {}\n",
    "    inter_dict = {}\n",
    "    mse_dict = {}\n",
    "\n",
    "    for fold in training_dist.keys():\n",
    "        perm_file_train = f\"fold_permutations/training/{fold}.csv\"\n",
    "        train_perms = pd.read_csv(perm_file_train, header=None)\n",
    "        perm_file_val = f\"fold_permutations/validation/{fold}.csv\"\n",
    "        val_perms = pd.read_csv(perm_file_val, header=None)\n",
    "\n",
    "        corr_vals = []\n",
    "        beta_vals = []\n",
    "        intercepts = []\n",
    "        mse_vals = []\n",
    "        ### do the test and perms for this fold\n",
    "        if skip_perms == False:\n",
    "            for perm_idx in range(train_perms.shape[1]):\n",
    "                t_idx = train_perms[perm_idx].values\n",
    "                v_idx = val_perms[perm_idx].values\n",
    "                r, beta, inter, mse = train_test_predict(\n",
    "                    training_dist[fold],\n",
    "                    training_beh[fold].iloc[t_idx],\n",
    "                    val_dist[fold],\n",
    "                    val_beh[fold],\n",
    "                )\n",
    "                corr_vals.append(r)\n",
    "                beta_vals.append(beta)\n",
    "                intercepts.append(inter)\n",
    "                mse_vals.append(mse)\n",
    "        else:\n",
    "            #             print('skipping permutation tests')\n",
    "            t_idx = train_perms[0].values\n",
    "            v_idx = val_perms[0].values\n",
    "            r, beta, inter, mse = train_test_predict(\n",
    "                training_dist[fold],\n",
    "                training_beh[fold].iloc[t_idx],\n",
    "                val_dist[fold],\n",
    "                val_beh[fold],\n",
    "            )\n",
    "            corr_vals.append(r)\n",
    "            beta_vals.append(beta)\n",
    "            intercepts.append(inter)\n",
    "            mse_vals.append(mse)\n",
    "        corr_dict[fold] = corr_vals\n",
    "        beta_dict[fold] = beta_vals\n",
    "        inter_dict[fold] = intercepts\n",
    "        mse_dict[fold] = mse_vals\n",
    "    return corr_dict, beta_dict, inter_dict, mse_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53217767",
   "metadata": {},
   "source": [
    "### a few plotting functions as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7475e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotModalityPerformance(ref_data, ablated_data, multimodal_model):\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.set_context(\"talk\", font_scale=0.7)  # Font scale reduced for small font sizes\n",
    "    #     plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "    # Prepare data\n",
    "    ref_melted = ref_data.reset_index().melt(\n",
    "        id_vars=\"index\", var_name=\"Fold\", value_name=\"Value\"\n",
    "    )\n",
    "    ref_melted[\"Type\"] = \"CD\"\n",
    "    ref_melted[\"Model\"] = [f\"CD-{i}\" for i in ref_melted[\"index\"]]\n",
    "\n",
    "    ablated_melted = ablated_data.reset_index().melt(\n",
    "        id_vars=\"index\", var_name=\"Fold\", value_name=\"Value\"\n",
    "    )\n",
    "    ablated_melted[\"Type\"] = \"FC\"\n",
    "    ablated_melted[\"Model\"] = [f\"FC-{i}\" for i in ablated_melted[\"index\"]]\n",
    "\n",
    "    combined_data = pd.concat([ref_melted, ablated_melted])\n",
    "    combined_data[\"Type\"] = pd.Categorical(\n",
    "        combined_data[\"Type\"], categories=[\"FC\", \"CD\"], ordered=True\n",
    "    )\n",
    "\n",
    "    multimodal_model = multimodal_model.melt(var_name=\"Fold\", value_name=\"Value\")\n",
    "    multimodal_model[\"index\"] = \"Joint\"\n",
    "    multimodal_model[\"Type\"] = \"FC+CD\"\n",
    "    multimodal_model[\"Model\"] = \"MultiModal-Joint\"\n",
    "    multimodal_model = multimodal_model[[\"index\", \"Fold\", \"Value\", \"Type\", \"Model\"]]\n",
    "    joint_data = combined_data[combined_data[\"index\"] == \"Joint\"]\n",
    "    joint_data = pd.concat([multimodal_model, joint_data])\n",
    "    joint_data[\"Type\"] = pd.Categorical(\n",
    "        joint_data[\"Type\"], categories=[\"FC\", \"CD\", \"FC+CD\"], ordered=True\n",
    "    )\n",
    "\n",
    "    # Define color palettes\n",
    "    palette_joint = {\"FC\": \"#8a2be2\", \"CD\": \"#6a0dad\", \"FC+CD\": \"#008080\"}\n",
    "    palette_pos = {\"FC\": \"#ff6347\", \"CD\": \"#ff4500\"}\n",
    "    palette_neg = {\"FC\": \"#4682b4\", \"CD\": \"#1e90ff\"}\n",
    "\n",
    "    # Create subplot layout with constrained figure size\n",
    "    fig, axes = plt.subplots(\n",
    "        1,\n",
    "        3,\n",
    "        figsize=(4.72, 1.8),\n",
    "        gridspec_kw={\"width_ratios\": [1.2, 1.2, 1.6]},\n",
    "        sharey=True,\n",
    "    )\n",
    "\n",
    "    # Generate Violin and Box plots\n",
    "    for ax, data, palette, title in zip(\n",
    "        axes,\n",
    "        [\n",
    "            combined_data[combined_data[\"index\"] == \"Positive\"],\n",
    "            combined_data[combined_data[\"index\"] == \"Negative\"],\n",
    "            joint_data,\n",
    "        ],\n",
    "        [palette_pos, palette_neg, palette_joint],\n",
    "        [\"Positive\", \"Negative\", \"Joint\"],\n",
    "    ):\n",
    "        sns.violinplot(\n",
    "            x=\"Type\",\n",
    "            y=\"Value\",\n",
    "            hue=\"Type\",\n",
    "            legend=False,\n",
    "            data=data,\n",
    "            ax=ax,\n",
    "            palette=palette,\n",
    "            inner=\"box\",\n",
    "            linewidth=1.5,\n",
    "        )\n",
    "        ax.set_title(title, fontsize=7)\n",
    "\n",
    "    # Style adjustments\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.tick_params(axis=\"x\", labelsize=7)\n",
    "        ax.tick_params(axis=\"y\", labelsize=7)\n",
    "        sns.despine(ax=ax, top=True, right=True, left=True, bottom=False)\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.5, linewidth=0.5)\n",
    "\n",
    "    axes[0].set_ylabel(\"Correlation (r)\", fontsize=7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea14831f",
   "metadata": {},
   "source": [
    "### Run single modality and joint modality models -- get performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d385a604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476/476 edges used in summary metric\n",
      "157/157 edges used in summary metric\n"
     ]
    }
   ],
   "source": [
    "dist_summary_measures = prepare_summary_measures(\n",
    "    \"ReadEng_Unadj\", [positiveDistances, negativeDistances], SchaeferDist, ablate=False\n",
    ")\n",
    "FC_summary_measures = prepare_summary_measures(\n",
    "    \"ReadEng_Unadj\", [positiveFC, negativeFC], SchaeferFC, ablate=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de3cf639",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dist, training_beh, val_dist, val_beh = clean_folds(\n",
    "    \"ReadEng_Unadj\", folds, conf_categories, subjSM, dist_summary_measures\n",
    ")\n",
    "\n",
    "training_FC, training_beh, val_FC, val_beh = clean_folds(\n",
    "    \"ReadEng_Unadj\", folds, conf_categories, subjSM, FC_summary_measures\n",
    ")\n",
    "## cleaning of the below 4 column set was quite different than cleaning apart\n",
    "multimodal = (\n",
    "    pd.concat([dist_summary_measures, FC_summary_measures], axis=1)\n",
    "    .T.reset_index()\n",
    "    .drop(\"index\", axis=1)\n",
    "    .T\n",
    ")\n",
    "TrainMMcleanAll, training_beh, valMMcleanAll, val_beh = clean_folds(\n",
    "    \"ReadEng_Unadj\", folds, conf_categories, subjSM, multimodal\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86652073",
   "metadata": {},
   "outputs": [],
   "source": [
    "### distance\n",
    "corrsDist, betasDist, intersDist, mseDist = fit_and_measure(\n",
    "    training_dist, training_beh, val_dist, val_beh, skip_perms=False\n",
    ")\n",
    "corrsDist = pd.DataFrame(corrsDist)\n",
    "print(f\"Mean prediction: {corrsDist.mean(axis=1)[0]}\")\n",
    "pvalDist = sum(corrsDist.mean(axis=1)[0] <= corrsDist.iloc[1:].mean(axis=1)) / len(\n",
    "    corrsDist\n",
    ")\n",
    "print(f\"pval: {pvalDist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73305c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fc\n",
    "corrsFC, betasFC, intersFC, mseFC = fit_and_measure(\n",
    "    training_FC, training_beh, val_FC, val_beh, skip_perms=False\n",
    ")\n",
    "corrsFC = pd.DataFrame(corrsFC)\n",
    "print(f\"Mean prediction: {corrsFC.mean(axis=1)[0]}\")\n",
    "pvalFC = sum(corrsFC.mean(axis=1)[0] <= corrsFC.iloc[1:].mean(axis=1)) / len(corrsFC)\n",
    "print(f\"pval: {pvalFC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcee2a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "### multimodal dist + fc\n",
    "corrsMM, betasMM, intersMM, mseMM = fit_and_measure(\n",
    "    TrainMMcleanAll, training_beh, valMMcleanAll, val_beh, skip_perms=False\n",
    ")\n",
    "corrsMM = pd.DataFrame(corrsMM)\n",
    "print(f\"Mean prediction: {corrsMM.mean(axis=1)[0]}\")\n",
    "pvalMM = sum(corrsMM.mean(axis=1)[0] <= corrsMM.iloc[1:].mean(axis=1)) / len(corrsMM)\n",
    "print(f\"pval: {pvalMM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fd030b",
   "metadata": {},
   "source": [
    "### Run Positive and negative single feature models for FC and Dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae885a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_analysis(\n",
    "    task, cv_folds, confounds, Beh, Dist, edges, skip_perms=False, ablation=False\n",
    "):\n",
    "    summary_measure = prepare_summary_measures(task, edges, Dist, ablate=ablation)\n",
    "    #     print('running')\n",
    "    ### clean all the data at once\n",
    "    training_dist, training_beh, val_dist, val_beh = clean_folds(\n",
    "        task, cv_folds, confounds, Beh, summary_measure\n",
    "    )\n",
    "\n",
    "    corrs, betas, inters, mse = fit_and_measure(\n",
    "        training_dist, training_beh, val_dist, val_beh, skip_perms=skip_perms\n",
    "    )\n",
    "\n",
    "    corr_df = pd.DataFrame(corrs)\n",
    "    print(f\"Mean performance: {corr_df.loc[0].mean()}\")\n",
    "    if skip_perms == False:\n",
    "        Pval = sum(corr_df.mean(axis=1)[0] <= corr_df.iloc[1:].mean(axis=1)) / len(\n",
    "            corr_df\n",
    "        )\n",
    "        print(f\"pval: {Pval} \\n\")\n",
    "\n",
    "    return corrs, betas, inters, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854a2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### distance\n",
    "print(\"Positive Distance Model\")\n",
    "posModelDist, pos_betasDist, _, _ = run_full_analysis(\n",
    "    tasks,\n",
    "    folds,\n",
    "    conf_categories,\n",
    "    subjSM,\n",
    "    SchaeferDist,\n",
    "    positiveDistances,\n",
    "    skip_perms=False,\n",
    "    ablation=False,\n",
    ")\n",
    "posModelDist = pd.DataFrame(posModelDist)\n",
    "print(\"\")\n",
    "print(\"Negative Distance Model\")\n",
    "negModelDist, neg_betasDist, _, _ = run_full_analysis(\n",
    "    tasks,\n",
    "    folds,\n",
    "    conf_categories,\n",
    "    subjSM,\n",
    "    SchaeferDist,\n",
    "    negativeDistances,\n",
    "    skip_perms=False,\n",
    "    ablation=False,\n",
    ")\n",
    "negModelDist = pd.DataFrame(negModelDist)\n",
    "print(\"\\n\")\n",
    "### FC\n",
    "print(\"Positive FC Model\")\n",
    "posModelFC, pos_betasFC, _, _ = run_full_analysis(\n",
    "    tasks,\n",
    "    folds,\n",
    "    conf_categories,\n",
    "    subjSM,\n",
    "    SchaeferFC,\n",
    "    positiveFC,\n",
    "    skip_perms=False,\n",
    "    ablation=False,\n",
    ")\n",
    "posModelFC = pd.DataFrame(posModelFC)\n",
    "print(\"\")\n",
    "print(\"Negative FC Model\")\n",
    "negModelFC, neg_betasFC, _, _ = run_full_analysis(\n",
    "    tasks,\n",
    "    folds,\n",
    "    conf_categories,\n",
    "    subjSM,\n",
    "    SchaeferFC,\n",
    "    negativeFC,\n",
    "    skip_perms=False,\n",
    "    ablation=False,\n",
    ")\n",
    "negModelFC = pd.DataFrame(negModelFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5395657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = pd.concat([corrsDist.loc[0], posModelDist.loc[0], negModelDist.loc[0]], axis=1)\n",
    "dist.columns = [\"Joint\", \"Positive\", \"Negative\"]\n",
    "dist = dist.T\n",
    "func = pd.concat([corrsFC.loc[0], posModelFC.loc[0], negModelFC.loc[0]], axis=1)\n",
    "func.columns = [\"Joint\", \"Positive\", \"Negative\"]\n",
    "func = func.T\n",
    "gd_and_fc = pd.DataFrame(corrsMM.loc[0])\n",
    "\n",
    "dist.to_csv(\"distance_CV_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e41e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotModalityPerformance(dist, func, gd_and_fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce071a52",
   "metadata": {},
   "source": [
    "### Are the models statistically different? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3889017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c61c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### pos and neg FC vs Dsit\n",
    "wilcx_pos = wilcoxon(func.loc[\"Positive\"], dist.loc[\"Positive\"])\n",
    "wilcx_neg = wilcoxon(func.loc[\"Negative\"], dist.loc[\"Negative\"])\n",
    "\n",
    "### joint model testing\n",
    "wilcx_jnt = wilcoxon(func.loc[\"Joint\"], dist.loc[\"Joint\"])\n",
    "wilcx_jnt_MM_dist = wilcoxon(dist.loc[\"Joint\"], gd_and_fc.values.squeeze())\n",
    "wilcx_jnt_MM_FC = wilcoxon(dist.loc[\"Joint\"], gd_and_fc.values.squeeze())\n",
    "### look at the p-vals and correct them too\n",
    "p_vals = [\n",
    "    wilcx_pos[1],\n",
    "    wilcx_neg[1],\n",
    "    wilcx_jnt[1],\n",
    "    wilcx_jnt_MM_FC[1],\n",
    "    wilcx_jnt_MM_dist[1],\n",
    "]\n",
    "corrected_p_vals = multipletests(p_vals, method=\"bonferroni\")[1]\n",
    "summary_df = pd.DataFrame(\n",
    "    [p_vals, corrected_p_vals],\n",
    "    columns=[\"Positive\", \"Negative\", \"Joint\", \"FC+CD vs Func\", \"FC+CD vs Dist\"],\n",
    "    index=[\"p_vals\", \"corrected p\"],\n",
    ")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dffcf4",
   "metadata": {},
   "source": [
    "We see that the FC and CD Joint feature models don't pass significance. \n",
    "We test now for equivalence of the two joint models using two one sided wilcoxon tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de337271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### here is the code for equivalence testing.\n",
    "#### equivalence testing set up\n",
    "\n",
    "\n",
    "def bootstrap_ci(data, n_bootstrap=10000, ci=95, seed=42):\n",
    "    \"\"\"\n",
    "    Calculates the confidence interval for the mean of a dataset using bootstrapping.\n",
    "\n",
    "    Args:\n",
    "        data (array-like): The dataset from which to calculate the mean.\n",
    "        n_bootstrap (int): The number of bootstrap samples to generate.\n",
    "        ci (int): The desired confidence level (e.g., 95 for 95% CI).\n",
    "        seed (int): Seed for the random number generator for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Lower and upper bounds of the confidence interval.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)  # Set seed for reproducibility\n",
    "    sample_size = len(data)\n",
    "    boot_means = []\n",
    "\n",
    "    # Generate bootstrap samples and compute the mean of each sample\n",
    "    for _ in range(n_bootstrap):\n",
    "        boot_sample = np.random.choice(data, size=sample_size, replace=True)\n",
    "        boot_mean = np.mean(boot_sample)\n",
    "        boot_means.append(boot_mean)\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    lower_bound = np.percentile(boot_means, (100 - ci) / 2)\n",
    "    upper_bound = np.percentile(boot_means, 100 - (100 - ci) / 2)\n",
    "    #     print(lower_bound,upper_bound,np.mean(data))\n",
    "\n",
    "    return upper_bound - lower_bound\n",
    "\n",
    "\n",
    "#### we can use the confidence interval to set the bounds for the tost.\n",
    "### if it is above 0.03 then we'll set to 0.03 to keep tight bounds\n",
    "\n",
    "\n",
    "def wilcoxon_tost(data1, data2, bound=0.03):\n",
    "    \"\"\"\n",
    "    Performs a Two One-Sided Tests (TOST) for equivalence using the Wilcoxon signed-rank test.\n",
    "\n",
    "    Args:\n",
    "        data1 (array-like): First dataset, typically predictions or measurements from one model.\n",
    "        data2 (array-like): Second dataset, typically predictions or measurements from another model.\n",
    "        bound (float): The equivalence margin or bound within which differences are considered practically equivalent.\n",
    "\n",
    "    Returns:\n",
    "        float: The maximum p-value from the two one-sided tests. A small value (< alpha level, typically 0.05)\n",
    "               suggests that the difference between data1 and data2 is not practically significant.\n",
    "    \"\"\"\n",
    "    # Convert to arrays and calculate differences\n",
    "    diffs = data1 - data2\n",
    "\n",
    "    # Perform TOST using Wilcoxon signed-rank tests\n",
    "    p_lower = wilcoxon(diffs - bound, alternative=\"less\", correction=True).pvalue\n",
    "    p_upper = wilcoxon(diffs + bound, alternative=\"greater\", correction=True).pvalue\n",
    "\n",
    "    # Return the maximum p-value to apply the TOST principle\n",
    "    return max(p_lower, p_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c58717",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_equiv_joint = wilcoxon_tost(dist.loc[\"Joint\"], func.loc[\"Joint\"])\n",
    "print(\n",
    "    f\"The p-value of the equivalence test between the CD and FC models is \\n {p_equiv_joint}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ab426",
   "metadata": {},
   "source": [
    "The p-values imply that the Joint FC and CD models are neither equivalent, nor statistically different. \n",
    "\n",
    "They're somewhere in between"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8edcf8",
   "metadata": {},
   "source": [
    "## Ablation of summary features in the distance models\n",
    "To determine what distances matter in our models we'll now ablate the summary features and retrain and evaluate with CV. We will not run permutations here as we're only interested in how including certain sets of distances effects predictive accuracy in the joint distance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1364a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelAblation(\n",
    "    tasks, folds, conf_categories, subjSM, SchaeferDist, Clusters, Distances\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs analysis on provided clusters and calculates correlations, p-values, and MSE.\n",
    "\n",
    "    Parameters:\n",
    "    - tasks: Information about tasks (global variable).\n",
    "    - folds: Number of folds for cross-validation (global variable).\n",
    "    - conf_categories: Configuration categories (global variable).\n",
    "    - subjSM: Subject similarity matrix (global variable).\n",
    "    - SchaeferDist: Schaefer Distance Matrix (global variable).\n",
    "    - LnegClusters: Dictionary of negative clusters.\n",
    "    - negativeDistances: Negative distance matrix.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple of dictionaries containing correlations, p-values, mean squared errors, and MSE for each cluster.\n",
    "    \"\"\"\n",
    "    L_corrs = {}\n",
    "    L_r = {}\n",
    "    #     L_p = {}\n",
    "    L_mse = {}\n",
    "    L_betas = {}\n",
    "    for cluster in Clusters:\n",
    "        print(f\"using only {cluster}\")\n",
    "\n",
    "        ablated, betas, _, mse = run_full_analysis(\n",
    "            tasks,\n",
    "            folds,\n",
    "            conf_categories,\n",
    "            subjSM,\n",
    "            SchaeferDist,\n",
    "            Distances,\n",
    "            skip_perms=True,\n",
    "            ablation=Clusters[cluster],\n",
    "        )\n",
    "\n",
    "        # Calculate correlations and other statistics\n",
    "        L_betas[cluster] = betas\n",
    "        df_ablated = pd.DataFrame(ablated)\n",
    "        L_corrs[cluster] = df_ablated.iloc[0]\n",
    "        ablated_mean = df_ablated.mean(axis=1).iloc[0]\n",
    "        #         p_value = (df_ablated.mean(axis=1).iloc[0] <= df_ablated.mean(axis=1).iloc[1:]).sum() / len(df_ablated.mean(axis=1))\n",
    "\n",
    "        # Print cluster information\n",
    "        #         print(f'cluster {cluster}')\n",
    "        print(f\"\")\n",
    "\n",
    "        # Store results in dictionaries\n",
    "        L_r[cluster] = ablated_mean\n",
    "        #         L_p[cluster] = p_value\n",
    "        L_mse[cluster] = mse\n",
    "\n",
    "    return L_corrs, L_r, L_mse, L_betas\n",
    "\n",
    "\n",
    "#### function to get list of distances touching a given Yeo network in Schaefer atlas\n",
    "def rsn_ablation_lists(dists):\n",
    "    redes = [\"Vis\", \"SomMot\", \"DorsAttn\", \"SalVentAttn\", \"Limbic\", \"Cont\", \"Default\"]\n",
    "\n",
    "    nwork_dists = {}\n",
    "    for red in redes:\n",
    "        nwork_dists[f\"Network: {red}\"] = [i for i in dists if red in i]\n",
    "    return nwork_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d257bd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "### set up the network specific distances\n",
    "reading_dist_neg = negativeDistances[\"ReadEng_Unadj\"]\n",
    "rsns_neg_dists = rsn_ablation_lists(reading_dist_neg)\n",
    "reading_dist_pos = positiveDistances[\"ReadEng_Unadj\"]\n",
    "rsns_pos_dists = rsn_ablation_lists(reading_dist_pos)\n",
    "joint_rns = {}\n",
    "for i, j in zip(rsns_neg_dists, rsns_pos_dists):\n",
    "    joint_rns[i] = rsns_neg_dists[i] + rsns_pos_dists[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb6dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### run the network specific distance models\n",
    "corrsJNT_rsn, _, _, _ = ModelAblation(\n",
    "    tasks,\n",
    "    folds,\n",
    "    conf_categories,\n",
    "    subjSM,\n",
    "    SchaeferDist,\n",
    "    joint_rns,\n",
    "    [positiveDistances, negativeDistances],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce5d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrsJNT_rsn = pd.DataFrame(corrsJNT_rsn)\n",
    "corrsJNT_rsn.to_csv(\"./network_centered_CV_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b4de58",
   "metadata": {},
   "source": [
    "## Get pairwise distance sets between RSNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb9b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsn_ablation_lists(pos_dist, neg_dist):\n",
    "    redes = [\"Vis\", \"SomMot\", \"DorsAttn\", \"SalVentAttn\", \"Limbic\", \"Cont\", \"Default\"]\n",
    "    inclusion = {}\n",
    "    for red in redes:\n",
    "        red_pos = [i for i in pos_dist if red in i]\n",
    "        red_neg = [i for i in neg_dist if red in i]\n",
    "        nw_dist = red_pos + red_neg\n",
    "\n",
    "        for subred in redes:\n",
    "            sr_dist = [i for i in nw_dist if subred in i]\n",
    "            if subred == red:\n",
    "                within_nw = []\n",
    "                for i in nw_dist:\n",
    "                    edge = i.split(\"--\")\n",
    "                    node1 = edge[0]\n",
    "                    node2 = edge[1]\n",
    "                    if red in node1 and red in node2:\n",
    "                        within_nw.append(i)\n",
    "                sr_dist = within_nw\n",
    "\n",
    "            inclusion[f\"{red}--{subred}\"] = sr_dist\n",
    "\n",
    "    return inclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c34506",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_ablations = rsn_ablation_lists(reading_dist_pos, reading_dist_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75999615",
   "metadata": {},
   "outputs": [],
   "source": [
    "### note this can take a while. saved results can be loaded\n",
    "corrsJNT_pairwise_ablated, _, _, _pairwise_betas = ModelAblation(\n",
    "    tasks,\n",
    "    folds,\n",
    "    conf_categories,\n",
    "    subjSM,\n",
    "    SchaeferDist,\n",
    "    pairwise_ablations,\n",
    "    [positiveDistances, negativeDistances],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ba3c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "internetwork_models = pd.DataFrame(corrsJNT_pairwise_ablated)\n",
    "internetwork_models.to_csv(\"internetwork_models_CV_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bf56a1",
   "metadata": {},
   "source": [
    "### Visualize ablated models and test equivalence among them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f801ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### plotting function\n",
    "import matplotlib.colors\n",
    "\n",
    "\n",
    "def plot_performance(\n",
    "    data, x_col, y_col, figsize_mm=(175, 110), rotation_angle=45, col_range=None\n",
    "):\n",
    "    # Define specific color mappings\n",
    "    palette = {\n",
    "        \"Full Model\": \"#60C2A5\",\n",
    "        \"Vis\": \"#a252ad\",\n",
    "        \"SM\": \"#789ac0\",\n",
    "        \"Lim\": \"#f6fdc9\",\n",
    "        \"SAN\": \"#e065fe\",\n",
    "        \"DAN\": \"#409832\",\n",
    "        \"Cont\": \"#f0b943\",\n",
    "        \"DMN\": \"#d8717c\",\n",
    "    }\n",
    "\n",
    "    # Calculate the mean of 'r' for each 'CD Included' category\n",
    "    means = data.groupby(x_col)[y_col].mean().reset_index()\n",
    "    # Sort the means\n",
    "    sorted_means = means.sort_values(y_col, ascending=False)\n",
    "\n",
    "    # Use the sorted order of 'CD Included' for plotting, potentially limited by col_range\n",
    "    if col_range and isinstance(col_range, int) and col_range < len(sorted_means):\n",
    "        sorted_categories = sorted_means[x_col].head(col_range).tolist()\n",
    "    else:\n",
    "        sorted_categories = sorted_means[x_col].tolist()\n",
    "\n",
    "    # Extend the palette to include all categories in your data, assigning a default neutral grey with transparency\n",
    "    all_categories = data[x_col].unique()\n",
    "    uniform_color = matplotlib.colors.to_rgba(\"#e6f2ee\", alpha=0.5)\n",
    "    palette.update({cat: uniform_color for cat in all_categories if cat not in palette})\n",
    "\n",
    "    # Set the categories with sorted order and defined colors\n",
    "    data[x_col] = pd.Categorical(\n",
    "        data[x_col], categories=sorted_categories, ordered=True\n",
    "    )\n",
    "\n",
    "    # Convert mm to inches for dimensions\n",
    "    width_in_inches = figsize_mm[0] / 25.4  # Convert mm to inches\n",
    "    height_in_inches = figsize_mm[1] / 25.4  # Convert mm to inches\n",
    "\n",
    "    # Set up the matplotlib figure with high DPI for publication quality\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(width_in_inches, height_in_inches), dpi=300)\n",
    "\n",
    "    ax = sns.boxplot(\n",
    "        data=data,\n",
    "        x=x_col,\n",
    "        y=y_col,\n",
    "        hue=x_col,\n",
    "        legend=False,\n",
    "        width=0.75,\n",
    "        palette=palette,\n",
    "    )\n",
    "\n",
    "    # Remove titles and labels (no overarching title, no x or y axis titles)\n",
    "    ax.set_title(\"\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "    # Despine for a cleaner look\n",
    "    sns.despine(ax=ax, top=True, right=True, left=True, bottom=True)\n",
    "\n",
    "    # Adjust tick parameters for better visibility\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=7)\n",
    "\n",
    "    # Rotate x labels for better fit and readability\n",
    "    ax.set_xticklabels(\n",
    "        ax.get_xticklabels(), rotation=rotation_angle, ha=\"center\", fontsize=5\n",
    "    )\n",
    "\n",
    "    # Ensure layout fits the constraints and is tight\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9350f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_centered = corrsJNT_rsn.copy()\n",
    "network_centered.rename(\n",
    "    columns={\n",
    "        \"Network: SomMot\": \"SM\",\n",
    "        \"Network: DorsAttn\": \"DAN\",\n",
    "        \"Network: SalVentAttn\": \"SAN\",\n",
    "        \"Network: Limbic\": \"Lim\",\n",
    "        \"Network: Default\": \"DMN\",\n",
    "        \"Network: Vis\": \"Vis\",\n",
    "        \"Network: Cont\": \"Cont\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d1415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "internetwork__performance = internetwork_models.mean()\n",
    "internetwork__performance.loc[\"Limbic--Limbic\"] = (\n",
    "    np.nan\n",
    ")  ### because there are no limbic to limbics\n",
    "internetwork__performance = pd.DataFrame(internetwork__performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b46da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_entries(network_list, abbrev_dict):\n",
    "    reformatted_list = []\n",
    "    for entry in network_list:\n",
    "        # Split the entry at '--'\n",
    "        parts = entry.split(\"--\")\n",
    "        # Replace each part if it is in the abbreviation dictionary\n",
    "        reformatted_parts = [abbrev_dict.get(part, part) for part in parts]\n",
    "        # Join the parts back together and add to the new list\n",
    "        reformatted_list.append(\"--\".join(reformatted_parts))\n",
    "    return reformatted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed2f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "### let's remove repeats from the internetwork columns\n",
    "dists = internetwork_models.columns\n",
    "unique_dists = set()\n",
    "\n",
    "for in_dist in dists:\n",
    "    part1, part2 = in_dist.split(\"--\")\n",
    "    # Store the sorted tuple (to handle symmetry) in the set\n",
    "    unique_dists.add(tuple(sorted([part1, part2])))\n",
    "\n",
    "# Convert the tuples back to the original format\n",
    "unique_internetworks = [\"--\".join(pair) for pair in unique_dists]\n",
    "abbreviation_dict = {\n",
    "    \"SomMot\": \"SM\",\n",
    "    \"DorsAttn\": \"DAN\",\n",
    "    \"SalVentAttn\": \"SAN\",\n",
    "    \"Limbic\": \"Lim\",\n",
    "    \"Default\": \"DMN\",\n",
    "}\n",
    "unique_internetworks_new = reformat_entries(unique_internetworks, abbreviation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea02d9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter2plot = internetwork_models[unique_internetworks].rename(\n",
    "    columns=dict(zip(unique_internetworks, unique_internetworks_new))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989b8994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### let's get all model performance into one df\n",
    "all_joint_models = pd.concat([dist.loc[\"Joint\"], network_centered, inter2plot], axis=1)\n",
    "all_joint_models.rename(columns={\"Joint\": \"Full Model\"}, inplace=True)\n",
    "### drop the limbic--limbic there were not distances at all here so it ended up using the full model there. it can thus be ignored\n",
    "all_joint_models.drop(columns=\"Lim--Lim\", inplace=True)\n",
    "\n",
    "### sort by mean performance\n",
    "all_joint_models = all_joint_models[\n",
    "    all_joint_models.mean(axis=0).sort_values(ascending=False).keys()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a8bf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=0.5, rc={\"lines.linewidth\": 2.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec219dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(\n",
    "    data=all_joint_models.melt(var_name=\"CD Included\", value_name=\"r\"),\n",
    "    x_col=\"CD Included\",\n",
    "    y_col=\"r\",\n",
    "    figsize_mm=(88, 70),\n",
    "    col_range=5,\n",
    "    rotation_angle=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9494a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(\n",
    "    data=all_joint_models.melt(var_name=\"CD Included\", value_name=\"r\"),\n",
    "    x_col=\"CD Included\",\n",
    "    y_col=\"r\",\n",
    "    figsize_mm=(88, 70),\n",
    "    rotation_angle=90,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c619350a",
   "metadata": {},
   "source": [
    "### Let's check equivalence among all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9d26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52874156",
   "metadata": {},
   "outputs": [],
   "source": [
    "### test pairwise equivalence of all 35 models\n",
    "def tost_a_df(df):\n",
    "    results_dict = {}\n",
    "    bounds_dict = {}\n",
    "    for i in tqdm(df.keys()):\n",
    "        ref_bounds = bootstrap_ci(df[i])\n",
    "        for j in df.keys():\n",
    "            if i == j or (j, i) in results_dict.keys():\n",
    "                pass\n",
    "            else:\n",
    "                pair_bounds = bootstrap_ci(df[j])\n",
    "                bound = min(ref_bounds, pair_bounds)\n",
    "\n",
    "                if bound > 0.03:\n",
    "                    bound = 0.03\n",
    "                p = wilcoxon_tost(df[i], df[j], bound=bound)\n",
    "                results_dict[(i, j)] = p\n",
    "                bounds_dict[(i, j)] = bound\n",
    "    return results_dict, bounds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51e64a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_equiv = tost_a_df(all_joint_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9662885",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_equiv_df = pd.DataFrame([model_equiv[0]])\n",
    "corrections = multipletests(\n",
    "    model_equiv_df.values.squeeze(), method=\"fdr_bh\", alpha=0.05\n",
    ")\n",
    "passed_tests = np.where(corrections[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3c14ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_passing = model_equiv_df.iloc[:, passed_tests]\n",
    "models_passing.index = [\"p_raw\"]\n",
    "models_passing = models_passing.T\n",
    "models_passing[\"p_fdr\"] = corrections[1][corrections[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08706ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_passing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d085de15",
   "metadata": {},
   "source": [
    "### Finished\n",
    "Continue to netbook 4 for feature visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
